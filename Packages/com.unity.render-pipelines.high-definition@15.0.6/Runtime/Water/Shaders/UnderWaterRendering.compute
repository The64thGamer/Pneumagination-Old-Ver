#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal
//#pragma enable_d3d11_debug_symbols

// Line evaluation
#pragma kernel ClearWaterLine
#pragma kernel LineEvaluation1D
#pragma kernel BoundsPropagation

// Underwater rendering
#pragma kernel UnderWater UNDER_WATER_KERNEL=UnderWater
#pragma kernel UnderWaterDirectionalCaustics UNDER_WATER_KERNEL=UnderWaterDirectionalCaustics DIRECTIONAL_LIGHT_CAUSTICS

// HDRP generic includes
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/Lighting.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Material.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/NormalSurfaceGradient.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Water/Water.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Water/Shaders/UnderWaterUtilities.hlsl"

TEXTURE2D_X(_DepthTexture);
TEXTURE2D_X_UINT2(_StencilTexture);

// 1D WaterLine Buffer, contains the vertical (along upVector) height of the water line
// first two elements contains the horizontal min and max of the visible water line
RWStructuredBuffer<uint> _WaterLineRW;

[numthreads(8, 1, 1)]
void ClearWaterLine(uint dispatchThreadId : SV_DispatchThreadID)
{
    _WaterLineRW[dispatchThreadId] = 0;
}

[numthreads(8, 8, 1)]
void LineEvaluation1D(uint3 currentCoord : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(currentCoord.z);

    // Early exit pixels containing no water
    float depthValue = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord.xy).x;
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE)
        return;
    uint stencilValue = GetStencilValue(LOAD_TEXTURE2D_X(_StencilTexture, currentCoord.xy));
    if ((stencilValue & STENCILUSAGE_WATER_SURFACE) == 0)
        return;

    // Output to the water line buffer
    float2 upVector = float2(_UpDirectionX, _UpDirectionY);
    float2 rightVector = float2(_UpDirectionY, -_UpDirectionX);

    uint posX = round(dot((float2)currentCoord.xy, rightVector) - _BoundsSS.x);
    uint posY = round(dot((float2)currentCoord.xy, upVector) - _BoundsSS.z);

    // We use InterlockedMax with depth values on higher bits to find closest pixel to camera
    // We store the pixel height as payload in the lower bits to retrieve the waterline height later
    uint height = posY + 1; // Add one to make sure 0 means missing value
    uint packedValue = PackFloatToUInt(depthValue, 16, 16) | (height & 0xFFFF);

    uint idx = min(posX + 2, _BufferStride) + currentCoord.z * _BufferStride;
    InterlockedMax(_WaterLineRW[idx], packedValue);
}

#define GROUP_SIZE 128
#ifndef PLATFORM_SUPPORTS_WAVE_INTRINSICS
groupshared uint2 gs_bounds[GROUP_SIZE];
#endif

uint2 ParallelReduction(uint threadIdx, uint2 bounds)
{
#ifdef PLATFORM_SUPPORTS_WAVE_INTRINSICS
    return uint2(WaveActiveMin(bounds.x), WaveActiveMax(bounds.y));
#else
    gs_bounds[threadIdx] = bounds;

    GroupMemoryBarrierWithGroupSync();

    UNITY_UNROLL
    for (uint s = GROUP_SIZE / 2u; s > 0u; s >>= 1u)
    {
        if (threadIdx < s)
        {
            gs_bounds[threadIdx] = uint2(
                min(gs_bounds[threadIdx].x, gs_bounds[threadIdx + s].x),
                max(gs_bounds[threadIdx].y, gs_bounds[threadIdx + s].y)
            );
        }

        GroupMemoryBarrierWithGroupSync();
    }

    return gs_bounds[0];
#endif
}

[numthreads(GROUP_SIZE, 1, 1)]
void BoundsPropagation(uint2 currentCoord : SV_DispatchThreadID, uint groupThreadId : SV_GroupThreadID)
{
    const uint2 maxBounds = uint2(0xFFFFFFFF, 0);

    // This kernel finds the leftmost and rightmost pixels containing water
    uint xr = currentCoord.y * _BufferStride;
    uint coord = min(currentCoord.x + 2, _BufferStride) + xr;
    uint packedValue = _WaterLineRW[coord];
    uint2 bounds = packedValue == 0 ? maxBounds : (uint2)currentCoord.x;
    bounds = ParallelReduction(groupThreadId, bounds);

    if (groupThreadId == 0)
    {
        InterlockedMax(_WaterLineRW[0 + xr], 0xFFFFFFFF - bounds.x);
        InterlockedMax(_WaterLineRW[1 + xr], bounds.y);
    }

    uint maxHeight = ceil(_BoundsSS.w - _BoundsSS.z);
    float distanceToSurface = GetWaterCameraHeight();
    float distanceToWaterLine = distanceToSurface > 0 ? 0.0f : maxHeight;
    if (abs(distanceToSurface) > _WaterTransitionSize)
    {
        _WaterLineRW[coord] = ((uint)distanceToWaterLine + 1) & 0xFFFF;
        return;
    }

    if (packedValue != 0)
        return;

    // Patch holes of less than GROUP_SIZE pixels
    if (any(bounds != maxBounds))
    {
        uint bound = bounds.x != maxBounds.x ? bounds.x : bounds.y;
        packedValue = _WaterLineRW[bound + 2 + xr];
    }

    // Last hope to patch a hole
    if (packedValue == 0) packedValue = _WaterLineRW[0 + 2 + xr];
    if (packedValue == 0) packedValue = _WaterLineRW[(_BoundsSS.y-_BoundsSS.x) + 2 + xr];

    if (packedValue != 0)
    {
        distanceToWaterLine = (packedValue & 0xFFFF) - 1;
        distanceToWaterLine = round(distanceToWaterLine / maxHeight) * maxHeight;
    }

    _WaterLineRW[coord] = ((uint)distanceToWaterLine + 1) & 0xFFFF;
}

// Input color value
TEXTURE2D_X(_CameraColorTexture);

// Output textures of the kernels
RW_TEXTURE2D_X(float4, _CameraColorTextureRW);

// Need to be moved to a constant buffer
[numthreads(8, 8, 1)]
void UNDER_WATER_KERNEL(uint3 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Compute the pixel position to process
    uint2 currentCoord = groupId * 8 + groupThreadId;

    // Fetch the direct camera color
    float4 camColor = LOAD_TEXTURE2D_X(_CameraColorTexture, currentCoord);

    // Only apply on pixels underwater
    if (GetUnderWaterDistance(currentCoord) > 0.0f)
    {
        _CameraColorTextureRW[COORD_TEXTURE2D_X(currentCoord)] = camColor;
        return;
    }

    // Grab the vertical distance to the surface
    float distanceToSurface = GetWaterCameraHeight();

    // Read the depth value
    float depthValue = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).x;
    PositionInputs posInput = GetPositionInput(currentCoord, _ScreenSize.zw, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);
    uint stencilValue = GetStencilValue(LOAD_TEXTURE2D_X(_StencilTexture, currentCoord));

    // Approximate the pixel depth based on the distance from camera to surface
    float depth = max(-dot(posInput.positionWS, _WaterUpDirection.xyz) - distanceToSurface, 0);

    // Evaluate the caustics for this position
    float caustics = 1;

    // Read the stencil value
    if ((stencilValue & STENCILUSAGE_WATER_SURFACE) == 0)
    {
        caustics = EvaluateSimulationCaustics(posInput.positionWS, depth, currentCoord * _ScreenSize.zw);
        #if defined(DIRECTIONAL_LIGHT_CAUSTICS)
        // In case the user asked for shadow to explicitly be affected by shadows
        if (_CausticsShadowIntensity < 1.0 && _DirectionalShadowIndex >= 0)
        {
            HDShadowContext shadowContext = InitShadowContext();
            DirectionalLightData light = _DirectionalLightDatas[_DirectionalShadowIndex];
            // TODO: this will cause us to load from the normal buffer first. Does this cause a performance problem?
            float3 L = -light.forward;
            // Is it worth sampling the shadow map?
            float sunShadow = 1.0f;
            if ((light.lightDimmer > 0) && (light.shadowDimmer > 0))
            {
                sunShadow = lerp(_CausticsShadowIntensity, 1.0, GetDirectionalShadowAttenuation(shadowContext, posInput.positionSS, posInput.positionWS, L, light.shadowIndex, L));
            }
            caustics = (caustics - 1)  * sunShadow + 1;
        }
        #endif
    }

    // Evaluate the fog of the target surface
    float cameraDistance = depthValue == UNITY_RAW_FAR_CLIP_VALUE ? _ProjectionParams.z : length(posInput.positionWS);
    float waterDistance = (cameraDistance + depth) / _MaxViewDistanceMultiplier;

    // Evaluate the absorption tint (match ComputeWaterRefractionParams)
    float3 waterAbsorption = exp(-waterDistance * _OutScatteringCoeff * (1.0 - _WaterRefractionColor.xyz));
    const float3 farColor = _WaterScatteringColor.xyz * lerp(1.0, _WaterAmbientProbe.w * GetCurrentExposureMultiplier(), _UnderWaterAmbientProbeContribution);
    const float3 clearColor = camColor.xyz * caustics;
    float3 underWaterColor = lerp(farColor, clearColor, waterAbsorption);

    // Output the camera color
    _CameraColorTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(underWaterColor, 1.0);
}
